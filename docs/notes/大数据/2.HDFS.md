# HDFS

### 理论知识点

- 存储模型
- 架构设计
- 角色功能
- 元数据持久化
- 安全模式
- 副本放置策略
- 读写流程
- 安全策略

#### 存储模型

- HDFS系统中，文件**线性**按**字节**切割成**块（Block）**，且每个块都有**偏移量（offset）**和**id**

  <img src="../../images/2020020622351866.png" alt="在这里插入图片描述" style="zoom: 67%;" />

- 各文件block大小可以不一样，比如A的块大小为4KB，B的块大小为8KB，但是每个文件中，除了最后一个块大小可以与其余块不同，其余块大小必须相同

- block块应根据硬件的I/O特性调整，在Hadoop 1.x版本时，block块大小默认为64MB，在Hadoop 2.x版本时，block块大小默认为128MB

- 由于是分布式环境，所以block块被分散在集群的各个节点中，但是block具有location（也就是说每个block块会有一个属性记录当前block块的地址）

- block块具有副本（replication），副本是满足可靠性和性能的关键。副本不能出现在同一节点（为了容灾考虑）上，副本之间没有主从概念，所有副本“地位”一致，比如block 1有3个副本，则说明整个集群中有3个block 1

- 文件上传时可以指定block块的大小和副本数，上传之后只能修改副本数，不能再更改block块的大小了

- 文件是一次写入多次读取的，且不支持修改文件，相当于只读。不修改的原因很简单，因为这会造成block块大小不一致，offset不成规律。但是允许在文件后追加数据，因为这不会更改前面block块的大小，不影响offset